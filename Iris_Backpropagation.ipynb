{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Backpropagation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPkoAo68eY2H5zE/M65/D3J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/G-Karishni/Pattern_Recognition/blob/main/Iris_Backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqaDdIM6Na3t"
      },
      "source": [
        "# Backpropagation - Supervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sHYEf0gNf4R"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYpCMNnZL86c"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6whtYE6NjGX"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d3PPAb2MHy-"
      },
      "source": [
        "iris = pd.read_csv(\"https://raw.githubusercontent.com/G-Karishni/Pattern_Recognition/main/Iris.csv\")\n",
        "iris = iris.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9a0rIcnMMBY",
        "outputId": "a190185c-44a8-421d-a1db-274003307a6a"
      },
      "source": [
        "X = iris[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
        "X = np.array(X)\n",
        "X[:5]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.4, 2.7, 5.3, 1.9],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [5.2, 3.5, 1.5, 0.2]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXzjyon9OFLV"
      },
      "source": [
        "One hot coding converts [0,1,2 = 'Setosa', 'Versicolor', 'Virginica'] to ([1, 0, 0], [0, 1, 0], [0, 0, 1]) form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Had2WYjMNMt",
        "outputId": "890a9cc2-114b-4303-f2e7-893220c99c06"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "Y = iris.Species\n",
        "Y = one_hot_encoder.fit_transform(np.array(Y).reshape(-1, 1))\n",
        "Y[:5]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6YPBm2CNl9R"
      },
      "source": [
        "Split train and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnBmGfsKMRGT"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC8bVwF_OpU3"
      },
      "source": [
        "The main function is NeuralNetwork, which will train the network for the specified number of epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30qgUqGIPDfp"
      },
      "source": [
        "*   epochs: Number of epochs. Here, epochs = 10.\n",
        "*   nodes: A list of integers. Each integer denotes the number of nodes in each layer. The length of this list denotes the number of layers.\n",
        "*   lr: The learning rate of the back-propagation training algorithm.Here, lr = 0.15."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX5bVaC6MT42"
      },
      "source": [
        "def NeuralNetwork(X_train, Y_train, X_val=None, Y_val=None, epochs=10, nodes=[], lr=0.15):\n",
        "    hidden_layers = len(nodes) - 1\n",
        "    weights = InitializeWeights(nodes)\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        weights = Train(X_train, Y_train, lr, weights)\n",
        "\n",
        "        if(epoch % 20 == 0):\n",
        "            print(\"Epoch {}\".format(epoch))\n",
        "            print(\"Training Accuracy:{}\".format(Accuracy(X_train, Y_train, weights)))\n",
        "            if X_val.any():\n",
        "                print(\"Validation Accuracy:{}\".format(Accuracy(X_val, Y_val, weights)))\n",
        "            \n",
        "    return weights"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZdjKNMBOtCF"
      },
      "source": [
        "At first, the weights of the network will get randomly initialized by InitializeWeights. Each element in the weights list represents a hidden layer. This function takes as input nodes and returns a multi-dimensional array, weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNXFYEsqMa61"
      },
      "source": [
        "def InitializeWeights(nodes):\n",
        "    \"\"\"Initialize weights with random values in [-1, 1] (including bias)\"\"\"\n",
        "    layers, weights = len(nodes), []\n",
        "    \n",
        "    for i in range(1, layers):\n",
        "        w = [[np.random.uniform(-1, 1) for k in range(nodes[i-1] + 1)]\n",
        "              for j in range(nodes[i])]\n",
        "        weights.append(np.matrix(w))\n",
        "    \n",
        "    return weights"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLUm96wdQdSW"
      },
      "source": [
        "*FeedForward propagation*\n",
        "\n",
        "1.   Each layer receives an input and computes an output. The output is computed by first calculating the dot product between the input and the weights of the layer and then passing this dot product through an activation function (in this case, the sigmoid function).\n",
        "2.   The output of each layer is the input of the next.\n",
        "3.   The input of the first layer is the feature vector.\n",
        "4.   The output of the final layer is the prediction of the network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s2Nh9D1MeMw"
      },
      "source": [
        "def ForwardPropagation(x, weights, layers):\n",
        "    activations, layer_input = [x], x\n",
        "    for j in range(layers):\n",
        "        activation = Sigmoid(np.dot(layer_input, weights[j].T))\n",
        "        activations.append(activation)\n",
        "        layer_input = np.append(1, activation) # Augment with bias\n",
        "    \n",
        "    return activations"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0pAT6ryQ1Hs"
      },
      "source": [
        "*Backward Propagation*\n",
        "\n",
        "1.  Calculate error at final output.\n",
        "2.  Propagate error backwards through the layers and perform corrections.\n",
        "3.  Calculate Delta: Back-propagated error of current layer times Sigmoid derivation of current layer activation.\n",
        "4.  Update Weights between current layer and previous layer: Multiply delta with activation of previous layer and learning rate, and add this product to weights of previous layer.\n",
        "5.  Calculate error for current layer. Remove the bias from the weights of the previous layer and multiply the result with delta to get error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzJV7z_MMhSu"
      },
      "source": [
        "def BackPropagation(y, activations, weights, layers):\n",
        "    outputFinal = activations[-1]\n",
        "    error = np.matrix(y - outputFinal) # Error at output\n",
        "    \n",
        "    for j in range(layers, 0, -1):\n",
        "        currActivation = activations[j]\n",
        "        \n",
        "        if(j > 1):\n",
        "            # Augment previous activation\n",
        "            prevActivation = np.append(1, activations[j-1])\n",
        "        else:\n",
        "            # First hidden layer, prevActivation is input (without bias)\n",
        "            prevActivation = activations[0]\n",
        "        \n",
        "        delta = np.multiply(error, SigmoidDerivative(currActivation))\n",
        "        weights[j-1] += lr * np.multiply(delta.T, prevActivation)\n",
        "        w = np.delete(weights[j-1], [0], axis=1) # Remove bias from weights\n",
        "        error = np.dot(delta, w) # Calculate error for current layer\n",
        "    \n",
        "    return weights"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_UJUmPqOyM0"
      },
      "source": [
        "Then, in each epoch, the weights will be updated by Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk0WyX1kMrht"
      },
      "source": [
        "def Train(X, Y, lr, weights):\n",
        "    layers = len(weights)\n",
        "    for i in range(len(X)):\n",
        "        x, y = X[i], Y[i]\n",
        "        x = np.matrix(np.append(1, x)) # Augment feature vector\n",
        "        \n",
        "        activations = ForwardPropagation(x, weights, layers)\n",
        "        weights = BackPropagation(y, activations, weights, layers)\n",
        "\n",
        "    return weights"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzywMswMNqdV"
      },
      "source": [
        "Activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrcqvjHOMuyc"
      },
      "source": [
        "def Sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def SigmoidDerivative(x):\n",
        "    return np.multiply(x, 1-x)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf2iwpAWMxj0"
      },
      "source": [
        "def Predict(item, weights):\n",
        "    layers = len(weights)\n",
        "    item = np.append(1, item) # Augment feature vector\n",
        "    \n",
        "    ##_Forward Propagation_##\n",
        "    activations = ForwardPropagation(item, weights, layers)\n",
        "    \n",
        "    outputFinal = activations[-1].A1\n",
        "    index = FindMaxActivation(outputFinal)\n",
        "\n",
        "    # Initialize prediction vector to zeros\n",
        "    y = [0 for i in range(len(outputFinal))]\n",
        "    y[index] = 1  # Set guessed class to 1\n",
        "\n",
        "    return y # Return prediction vector"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESZn8JvbM1ys"
      },
      "source": [
        "def FindMaxActivation(output):\n",
        "    \"\"\"Find max activation in output\"\"\"\n",
        "    m, index = output[0], 0\n",
        "    for i in range(1, len(output)):\n",
        "        if(output[i] > m):\n",
        "            m, index = output[i], i\n",
        "    \n",
        "    return index"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHc7s7MERDuj"
      },
      "source": [
        "Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpI_CgrlO5Bx"
      },
      "source": [
        "Finally, every 20 epochs accuracy both for the training and validation sets will be printed by the Accuracy function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4un7nJ0M4ty"
      },
      "source": [
        "def Accuracy(X, Y, weights):\n",
        "    \"\"\"Run set through network, find overall accuracy\"\"\"\n",
        "    correct = 0\n",
        "\n",
        "    for i in range(len(X)):\n",
        "        x, y = X[i], list(Y[i])\n",
        "        guess = Predict(x, weights)\n",
        "\n",
        "        if(y == guess):\n",
        "            # Guessed correctly\n",
        "            correct += 1\n",
        "\n",
        "    return correct / len(X)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XtVTJipM8Yx",
        "outputId": "00fe4027-8acd-4f83-a71d-10f344d098b8"
      },
      "source": [
        "f = len(X[0]) # Number of features\n",
        "o = len(Y[0]) # Number of outputs / classes\n",
        "\n",
        "layers = [f, 5, 10, o] # Number of nodes in layers\n",
        "lr, epochs = 0.15, 100\n",
        "\n",
        "weights = NeuralNetwork(X_train, Y_train, X_val, Y_val, epochs=epochs, nodes=layers, lr=lr);"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20\n",
            "Training Accuracy:0.9736842105263158\n",
            "Validation Accuracy:1.0\n",
            "Epoch 40\n",
            "Training Accuracy:0.956140350877193\n",
            "Validation Accuracy:1.0\n",
            "Epoch 60\n",
            "Training Accuracy:0.9035087719298246\n",
            "Validation Accuracy:1.0\n",
            "Epoch 80\n",
            "Training Accuracy:0.9736842105263158\n",
            "Validation Accuracy:1.0\n",
            "Epoch 100\n",
            "Training Accuracy:0.9736842105263158\n",
            "Validation Accuracy:1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpxfAEn4M-2H",
        "outputId": "9306d3b5-1afb-4149-9eef-b7a7590375f5"
      },
      "source": [
        "print(\"Testing Accuracy: {}\".format(Accuracy(X_test, Y_test, weights)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 0.9565217391304348\n"
          ]
        }
      ]
    }
  ]
}